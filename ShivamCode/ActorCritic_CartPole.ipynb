{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957589d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# import gym\n",
    "\n",
    "# env = gym.make('CartPole-v1') \n",
    "\"\"\" \n",
    "Observation:\n",
    "    Type: Box(4)\n",
    "    Num     Observation               Min                     Max\n",
    "    0       Cart Position             -4.8                    4.8\n",
    "    1       Cart Velocity             -Inf                    Inf\n",
    "    2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "    3       Pole Angular Velocity     -Inf                    Inf\n",
    "Actions:\n",
    "    Type: Discrete(2)\n",
    "    Num   Action\n",
    "    0     Push cart to the left\n",
    "    1     Push cart to the right\n",
    "    Note: The amount the velocity that is reduced or increased is not\n",
    "    fixed; it depends on the angle the pole is pointing. This is because\n",
    "    the center of gravity of the pole increases the amount of energy needed\n",
    "    to move the cart underneath it\n",
    "Reward:\n",
    "    Reward is 1 for every step taken, including the termination step\n",
    "Starting State:\n",
    "    All observations are assigned a uniform random value in [-0.05..0.05]\n",
    "Episode Termination:\n",
    "    Pole Angle is more than 12 degrees.\n",
    "    Cart Position is more than 2.4 (center of the cart reaches the edge of\n",
    "    the display).\n",
    "    Episode length is greater than 200.\n",
    "    Solved Requirements:\n",
    "    Considered solved when the average return is greater than or equal to\n",
    "    195.0 over 100 consecutive trials.\n",
    "\"\"\"\n",
    "\n",
    "X_range = [-4.8, 4.8]\n",
    "v_range = [-10, 10]#[-100000, 100000] #[float('-inf'), float('inf')]\n",
    "theta_range = [-24, 24]\n",
    "anglev_range = [-10, 10] #[-100000, 100000]#[float('-inf'), float('inf')]\n",
    "start_range = [-0.05, 0.05]\n",
    "\n",
    "terminating_cond =[2.4, 12, 200]\n",
    "\n",
    "action_set = [0,1] #left, right\n",
    "\n",
    "M = 3 # dimensionality of the fourier transform\n",
    "softmax_sigma = 0.1\n",
    "# gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e95edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_radian(ang):\n",
    "    return ang*np.pi/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9e6653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(action, x, x_dot, theta, theta_dot):\n",
    "    gravity = 9.8\n",
    "    masscart = 1.0\n",
    "    masspole = 0.1\n",
    "    total_mass = masspole + masscart\n",
    "    length = 0.5  # actually half the pole's length\n",
    "    polemass_length = masspole * length\n",
    "    force_mag = 10.0\n",
    "    tau = 0.02\n",
    "\n",
    "    force = force_mag if action == 1 else -force_mag\n",
    "    costheta = np.cos(theta) # theta in radians\n",
    "    sintheta = np.sin(theta)\n",
    "\n",
    "    # from gym https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
    "    temp = (force + polemass_length * theta_dot ** 2 * sintheta) / total_mass\n",
    "    thetaacc = (gravity * sintheta - costheta * temp) / (length * (4.0 / 3.0 - masspole * costheta ** 2 / total_mass))\n",
    "    xacc = temp - polemass_length * thetaacc * costheta / total_mass\n",
    "    \n",
    "    #euler\n",
    "    x = x + tau * x_dot\n",
    "    x_dot = x_dot + tau * xacc\n",
    "    theta = theta + tau * theta_dot\n",
    "    theta_dot = theta_dot + tau * thetaacc\n",
    "    \n",
    "    #semi euler\n",
    "    # x_dot = x_dot + tau * xacc\n",
    "    # x = x + tau * x_dot\n",
    "    # theta_dot = theta_dot + tau * thetaacc\n",
    "    # theta = theta + tau * theta_dot\n",
    "\n",
    "    return x, x_dot, theta, theta_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553be124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminating(x, x_dot, theta, theta_dot, step):\n",
    "    if x <= -terminating_cond[0] or x >= terminating_cond[0] or theta <= -in_radian(terminating_cond[1]) or theta >= in_radian(terminating_cond[1]) or step>=terminating_cond[2]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eca53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(x, x_dot, theta, theta_dot, step):\n",
    "    if is_terminating(x, x_dot, theta, theta_dot, step):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def normalize(x, x_dot, theta, theta_dot, cosineflag=True):\n",
    "    if cosineflag:\n",
    "        x = (x-X_range[0])/(X_range[1]-X_range[0])\n",
    "        theta = (theta-theta_range[0])/(theta_range[1]-theta_range[0])\n",
    "        x_dot = (x_dot - v_range[0])/(v_range[1] - v_range[0])\n",
    "        theta_dot = (theta_dot - anglev_range[0])/(anglev_range[1] - anglev_range[0])\n",
    "        \n",
    "    else:\n",
    "        x = 2*(x-X_range[0])/(X_range[1]-X_range[0]) -1\n",
    "        theta = 2*(theta-theta_range[0])/(theta_range[1]-theta_range[0]) -1\n",
    "        x_dot = 2*(x_dot - v_range[0])/(v_range[1] - v_range[0]) -1\n",
    "        theta_dot = 2*(theta_dot - anglev_range[0])/(anglev_range[1] - anglev_range[0]) -1\n",
    "\n",
    "    return  x, x_dot, theta, theta_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771026cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier(x, x_dot, theta, theta_dot, cosineflag=False): #4M+1 features\n",
    "    #normalize\n",
    "    x, x_dot, theta, theta_dot = normalize(x, x_dot, theta, theta_dot, cosineflag)\n",
    "    phi = [1]\n",
    "    if cosineflag:\n",
    "        for i in range(1, M+1):\n",
    "            phi.append(np.cos(i*np.pi*x))\n",
    "        for i in range(1, M+1):\n",
    "            phi.append(np.cos(i*np.pi*x_dot))\n",
    "        for i in range(1, M+1):\n",
    "            phi.append(np.cos(i*np.pi*theta))\n",
    "        for i in range(1, M+1):\n",
    "            phi.append(np.cos(i*np.pi*theta_dot))\n",
    "    else:\n",
    "        for i in range(1, M+1):\n",
    "            phi.append(np.sin(i*np.pi*x))\n",
    "        for i in range(1, M+1):\n",
    "            phi.append(np.sin(i*np.pi*x_dot))\n",
    "        for i in range(1, M+1):\n",
    "            phi.append(np.sin(i*np.pi*theta))\n",
    "        for i in range(1, M+1):\n",
    "            phi.append(np.sin(i*np.pi*theta_dot))\n",
    "    return np.array(phi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c314ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_action(policy_params, x, x_dot, theta, theta_dot):\n",
    "    \n",
    "    phi_s = fourier(x, x_dot, theta, theta_dot) # (4M+1, )\n",
    "    # print(policy_params.shape, phi_s.shape)\n",
    "    policy_val = np.dot(phi_s.T, policy_params) #(4M,1) (4M+1, 2)\n",
    "    policy_exp = np.exp(softmax_sigma*policy_val)\n",
    "    policy_exp /= np.sum(policy_exp)\n",
    "    # print(policy_exp, x, x_dot, theta, theta_dot)\n",
    "    return policy_exp #(2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c8894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACTOR_CRITIC(alpha_w, alpha_theta, gamma=1.0):\n",
    "    policy_params = np.random.normal(0, 0.1, (4*M+1,len(action_set))) #np.ones((4*M+1,len(action_set)))*(-0.01)\n",
    "    value_params = np.ones(4*M+1)*0.01\n",
    "    episode_length, avg_return = [], []\n",
    "\n",
    "    for iter in range(4000):\n",
    "        policy_params_temp = policy_params.copy()\n",
    "        #run episode\n",
    "        #initial state\n",
    "        x = np.random.uniform(start_range[0], start_range[1])\n",
    "        theta = np.random.uniform(start_range[0], start_range[1])\n",
    "        x_dot  = np.random.uniform(start_range[0], start_range[1])\n",
    "        theta_dot = np.random.uniform(start_range[0], start_range[1])\n",
    "        step = 1\n",
    "        _return = 0\n",
    "        \n",
    "        # #using gym\n",
    "        # x, x_dot, theta, theta_dot = env.reset() \n",
    "\n",
    "        #run epsidoe\n",
    "        while not is_terminating(x, x_dot, theta, theta_dot, step):\n",
    "            #choose action\n",
    "            curr_action = random.choices(action_set, softmax_action(policy_params, x, x_dot, theta, theta_dot))\n",
    "\n",
    "            # #using gym\n",
    "            # observation, curr_reward, done, info = env.step(curr_action)\n",
    "            # next_x, next_x_dot, next_theta, mext_theta_dot = observation\n",
    "\n",
    "            #next state\n",
    "            next_x, next_x_dot, next_theta, mext_theta_dot = transition(curr_action, x, x_dot, theta, theta_dot)\n",
    "            #reward\n",
    "            curr_reward = reward(next_x, next_x_dot, next_theta, mext_theta_dot, step)\n",
    "            _return += curr_reward*gamma**(step-1)\n",
    "            step += 1\n",
    "            print(x, x_dot, theta, theta_dot, curr_action, softmax_action(policy_params, x, x_dot, theta, theta_dot))\n",
    "\n",
    "            phi_s = fourier(x, x_dot, theta, theta_dot)\n",
    "            phi_next_s = fourier(next_x, next_x_dot, next_theta, mext_theta_dot)\n",
    "            if not is_terminating(next_x, next_x_dot, next_theta, mext_theta_dot, step):\n",
    "                delta = curr_reward +gamma*np.dot(phi_next_s, value_params) - np.dot(phi_s, value_params)\n",
    "            else:\n",
    "                delta = curr_reward - np.dot(phi_s, value_params)\n",
    "            #update value params\n",
    "            value_params += alpha_w*delta*phi_s\n",
    "            #update policy params\n",
    "            policy = softmax_action(policy_params, x, x_dot, theta, theta_dot)\n",
    "            if curr_action == 0:\n",
    "                policy_params[:,0] += alpha_theta*delta*(1-policy[0])*phi_s\n",
    "                policy_params[:,1] += alpha_theta*delta*(-1*policy[0])*phi_s\n",
    "                # print(curr_action, delta, policy)\n",
    "            if curr_action == 1:\n",
    "                policy_params[:,0] += alpha_theta*delta*(-policy[1])*phi_s\n",
    "                policy_params[:,1] += alpha_theta*delta*(1-policy[1])*phi_s\n",
    "\n",
    "            x, x_dot, theta, theta_dot = next_x, next_x_dot, next_theta, mext_theta_dot\n",
    "\n",
    "        episode_length.append(step)\n",
    "        avg_return.append(_return)\n",
    "        \n",
    "        print(\"\\n EPISODE LENGTH: \",step, \"CURR ITER: \", iter)\n",
    "        if np.mean(avg_return[max(0, iter-100): iter+1]) > 195.0:\n",
    "            print(\"Hooray... solved\")\n",
    "            break\n",
    "        max_diff = np.max(np.abs(policy_params_temp - policy_params))\n",
    "        print(\" Max diff: \",max_diff)\n",
    "        if max_diff/alpha_theta < 0.001: # 0.001 works with 1e-6 policy_step\n",
    "            break\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(avg_return)), avg_return)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Avg. return')\n",
    "    plt.savefig('graph_cartpole_actorcritic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e588cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.033637792137466815 0.020173748446503076 -0.040604825879938 -0.04118724339077337 [1] [0.4966 0.5034]\n",
      "-0.03323431716853675 -0.17434312350590514 -0.04142857074775347 0.23841302637755182 [1] [0.4977 0.5023]\n",
      "-0.03672117963865486 -0.3688494916489249 -0.036660310220202434 0.5177457211228799 [1] [0.4988 0.5012]\n",
      "-0.04409816947163336 -0.5634366095681704 -0.026305395797744838 0.7986545622090948 [0] [0.4998 0.5002]\n",
      "-0.055366901662996765 -0.7581879862490619 -0.010332304553562943 1.0829476664481719 [1] [0.5007 0.4993]\n",
      "-0.070530661387978 -0.9531720663087261 0.011326648775400495 1.3723705313205226 [0] [0.5015 0.4985]\n",
      "-0.08959410271415252 -1.1484337995866227 0.038774059401810945 1.6685743069441825 [0] [0.5023 0.4977]\n",
      "-0.11256277870588498 -1.3439844761902013 0.0721455455406946 1.9730765695210255 [0] [0.5029 0.4971]\n",
      "-0.139442468229689 -1.5397892933006692 0.11160707693111512 2.2872121514816826 [1] [0.5034 0.4966]\n",
      "-0.1702382540957024 -1.7357522972438075 0.15735131996074878 2.612072253556491 [0] [0.5037 0.4963]\n",
      "\n",
      " EPISODE LENGTH:  11 CURR ITER:  0\n",
      " Max diff:  0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha_w, alpha_theta = 1e-7, 5e-4\n",
    "ACTOR_CRITIC(alpha_w, alpha_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1af83e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
