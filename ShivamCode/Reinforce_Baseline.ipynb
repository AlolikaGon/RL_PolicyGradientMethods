{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2b6b1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6db3c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy parameterization: Softmax\n",
    "# State value parameterization: Linear\n",
    "# State feature vector representation: Fourier (as in HW2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ea869318",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3 # dimensionality of the fourier transform [2, 10]\n",
    "# mean_policy_vector = np.ones(2*M+1)*0.05 #some non-zero vector\n",
    "\n",
    "policy_params = np.ones((2*M+1,2))*0.01\n",
    "value_params = np.ones(2*M+1)*0.01\n",
    "\n",
    "softmax_sigma = 0.1\n",
    "# policy_params = np.zeros((np.power(M+1,2),2))\n",
    "# value_params = np.zeros(np.power(M+1,2))\n",
    "\n",
    "policy_step_size = 1e-7 #2e-9\n",
    "valueFunction_step_size = 1e-7\n",
    "gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cec8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c333bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e1680b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_s_cosine(given_x, given_v, cosineFlag):\n",
    "    normal_x = normalized_x(given_x, cosineFlag)\n",
    "    normal_v = normalized_v(given_v, cosineFlag)\n",
    "    feature_phi = np.zeros(2*M+1)\n",
    "#     feature_phi = np.zeros(np.power(M+1,2))\n",
    "    feature_phi[0] = 1\n",
    "    if cosineFlag:\n",
    "        for i in range(1, M+1):\n",
    "            feature_phi[i] = np.cos(i*np.pi*normal_x)\n",
    "        \n",
    "        for i in range(1, M+1):\n",
    "            feature_phi[M+i] = np.cos(i*np.pi*normal_v)\n",
    "\n",
    "#         for i in range(0,M+1):\n",
    "#             for j in range(0,M+1):\n",
    "#                 if i==0 or j==0:\n",
    "#                     feature_phi[(M+1)*i + j] = np.cos(np.pi*(i*normal_x + j*normal_v))\n",
    "#                 else:\n",
    "#                     feature_phi[(M+1)*i + j] = np.cos(np.pi*(i*normal_x + j*normal_v))\n",
    "    \n",
    "    else:\n",
    "        for i in range(1, M+1):\n",
    "            feature_phi[i] = np.sin(i*np.pi*normal_x)\n",
    "        \n",
    "        for i in range(1, M+1):\n",
    "            feature_phi[M+i] = np.sin(i*np.pi*normal_v)\n",
    "\n",
    "#         for i in range(0,M+1):\n",
    "#             for j in range(0,M+1):\n",
    "#                 if i==0 or j==0:\n",
    "#                     feature_phi[(M+1)*i + j] = np.cos(np.pi*(i*normal_x + j*normal_v))\n",
    "#                 else:\n",
    "#                     feature_phi[(M+1)*i + j] = np.cos(np.pi*(i*normal_x + j*normal_v))\n",
    "\n",
    "    return feature_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4dbbbf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_x(given_x, cosineFlag):\n",
    "    if cosineFlag:\n",
    "        return (given_x+1.2)/(0.5+1.2)\n",
    "    else:\n",
    "        return ((given_x+1.2)/(0.5+1.2))*2 - 1\n",
    "def normalized_v(given_v, cosineFlag):\n",
    "    if cosineFlag:\n",
    "        return (given_v+0.7)/(0.7+0.7)\n",
    "    else:\n",
    "        return ((given_v+0.7)/(0.7+0.7))*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4fbd6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runEpisode(policy_params, gamma):\n",
    "    \n",
    "    episode_trace = []\n",
    "    \n",
    "    total_reward = 0\n",
    "    x_0 = np.random.uniform(-0.6,-0.4,1)[0]\n",
    "    begin_state = (x_0,0)\n",
    "    \n",
    "    S_t = begin_state\n",
    "    S_t_plus_1 = begin_state\n",
    "    for t in range(0, 1000):\n",
    "        \n",
    "        state_feature_vector = phi_s_cosine(S_t[0], S_t[1], True)\n",
    "        state_feature_policy_param_product = np.dot(policy_params.T, state_feature_vector)\n",
    "        exp_terms = np.exp(softmax_sigma * state_feature_policy_param_product)\n",
    "        pi_values = exp_terms/np.sum(exp_terms)\n",
    "        \n",
    "        A_t = np.random.choice([-1,1], p=list(pi_values))\n",
    "        \n",
    "        max_action_idx = np.argmax(pi_values)\n",
    "        if max_action_idx==1:\n",
    "            A_t = 1\n",
    "        else:\n",
    "            A_t = -1\n",
    "        \n",
    "#         threshold = np.dot(state_feature_vector, given_theta)\n",
    "        \n",
    "#         print(threshold)\n",
    "        \n",
    "#         if threshold<=0:\n",
    "#             A_t = -1\n",
    "#         else:\n",
    "#             A_t = 1\n",
    "        \n",
    "        v_t_plus_1 = S_t[1] + 0.001*A_t - 0.0025*np.cos(3*S_t[0])\n",
    "        x_t_plus_1 = S_t[0] + v_t_plus_1\n",
    "        \n",
    "        \n",
    "        \n",
    "        if x_t_plus_1 < -1.2:\n",
    "            x_t_plus_1 = -1.2\n",
    "            v_t_plus_1 = 0\n",
    "        elif x_t_plus_1 > 0.5:\n",
    "            x_t_plus_1 = 0.5\n",
    "            v_t_plus_1 = 0\n",
    "        \n",
    "        if v_t_plus_1 < -0.7:\n",
    "            v_t_plus_1 = -0.7\n",
    "        elif v_t_plus_1 > 0.7:\n",
    "            v_t_plus_1 = 0.7\n",
    "        \n",
    "        S_t_plus_1 = (x_t_plus_1, v_t_plus_1)\n",
    "        \n",
    "        if x_t_plus_1 == 0.5:\n",
    "            print(\"Terminated\")\n",
    "            episode_trace.append((S_t, A_t, 0))\n",
    "            break\n",
    "        else:\n",
    "            episode_trace.append((S_t, A_t, -1))\n",
    "            total_reward += -1\n",
    "#         print(\"After \",total_reward)\n",
    "        \n",
    "\n",
    "        S_t = S_t_plus_1 #Incrementing time step\n",
    "    return episode_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc220d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#With baseline\n",
    "\n",
    "curr_iter = 0\n",
    "while(curr_iter<=5000):\n",
    "    curr_iter += 1\n",
    "    \n",
    "    episode_trace = runEpisode(policy_params, gamma)\n",
    "    print(\"\\n EPISODE LENGTH: \",len(episode_trace), \"CURR ITER: \", curr_iter)\n",
    "    policy_params_temp = policy_params.copy()\n",
    "    for a_step in range(len(episode_trace)):\n",
    "        G = 0\n",
    "        for idx in range(a_step, len(episode_trace)):\n",
    "            G += episode_trace[idx][2]\n",
    "        \n",
    "        state_t = episode_trace[a_step][0]\n",
    "        state_t_feature_vector = phi_s_cosine(state_t[0], state_t[1], True)\n",
    "\n",
    "        v_hat_s = np.dot(state_t_feature_vector, value_params)\n",
    "        delta = G - v_hat_s\n",
    "        \n",
    "        value_params += valueFunction_step_size*delta*state_t_feature_vector\n",
    "        \n",
    "\n",
    "        state_t_feature_policy_param_product = np.dot(policy_params.T, state_t_feature_vector)\n",
    "        \n",
    "        \n",
    "        exp_terms = np.exp(softmax_sigma*state_t_feature_policy_param_product)\n",
    "        pi_values = exp_terms/np.sum(exp_terms)\n",
    "        \n",
    "#         print(\"Pi values: \",pi_values)\n",
    "#         print(\"G: \",G,\". Delta: \",delta)\n",
    "        if episode_trace[a_step][1] == -1:\n",
    "            policy_params[:,0] += policy_step_size*delta*(1-pi_values[0])*state_t_feature_vector\n",
    "            policy_params[:,1] += policy_step_size*delta*(-pi_values[0])*state_t_feature_vector\n",
    "        else:\n",
    "            policy_params[:,0] += policy_step_size*delta*(-pi_values[1])*state_t_feature_vector\n",
    "            policy_params[:,1] += policy_step_size*delta*(1-pi_values[1])*state_t_feature_vector\n",
    "    \n",
    "    max_diff = np.max(np.abs(policy_params_temp - policy_params))\n",
    "    print(policy_step_size,\" Max diff: \",max_diff)\n",
    "#     if max_diff<policy_step_size*1e2 or len(episode_trace)<110:# 0.001 works with 1e-6 policy_step\n",
    "#         break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a42d6dbb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
